{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Shiyuan Wang\n",
    "- Yuntian Wu\n",
    "- Xinhao Zhao\n",
    "- Wenyu Zhong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- We would like to find which supervised machine learning algorithm performs best for classifying images.\n",
    "- For practice, we are using the CIFAR100 image dataset with 50,000 32x32 color training images and 10,000 test images which are labeled over 100 fine-grained classes grouped into 20 coarse-grained classes. Once we successfully implemented our project with the CIFAR 100 dataset, we will work on the dataset of Butterfly/Moth (link in the footnote section)\n",
    "- We will apply various classification algorithms to classify the images including KNN, random forest, decision tree, and potentially other algorithms.\n",
    "- The performance of the algorithms will be assessed by calculating their accuracy in correctly classifying images into their true classes. (e.g. F1 score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Image classification is a sub-field of computer vision that relies on analyzing the features extracted from images to label them accordingly. The general structure of image classification consists of these steps: image pre-processing, detection of an object, feature extraction and training, and classification of the object <a name=\"Sanghvinote\"></a>[<sup>[1]</sup>](#Sanghvinote). Image classification can be done with both supervised and unsupervised machine learning approaches; for our project, the main focus is comparing the performance of different supervised machine learning algorithms on the same dataset. The author Nithyashree V (2022)<a name=\"Nithyashree\"></a>[<sup>[2]</sup>](#Nithyashree)  provided a sample demonstration of supervised machine-learning approaches for image classification, which inspired us for our project. \n",
    "  The reason we picked our dataset of Butterfly vs Moth is that these two species are very similar in their appearance, but it is possible to differentiate them by identifying particular patterns such as frenulums and wings (The Library of Congress, 2019)<a name=\"sotanote\"></a>[<sup>[3]</sup>](#sota). Therefore, we are interested in whether we can train our machine learning models to distinguish between butterflies and moths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once).\n",
    "\n",
    "The problem we are solving is related to the performance of traditional machine learning algorithms, specifically Random Forest Classifier, KNN, Decision Tree Classifier, and Naive Bayes classifier, in image classification tasks. Despite being widely used, these algorithms have been found to have poor accuracies when performing image classification, which limits their applicability in real-world scenarios where accuracy is paramount. This problem is significant because image classification is a crucial task in many fields, such as healthcare, security, and autonomous driving, where accuracy is essential for reliable decision-making.\n",
    "\n",
    "To ensure the problem is quantifiable, measurable, and replicable, we can use standard datasets and evaluation metrics such as the MNIST and CIFAR-10 datasets and accuracy and F1-score as evaluation metrics. Cross-validation and random sampling techniques can be used to ensure that the results are consistent and reproducible. By employing these techniques, we can improve the accuracy of traditional machine learning algorithms and expand their applicability in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The dataset used for the project is the CIFAR-10 dataset, which is a Keras dataset and can be downloaded directly from the link: https://www.cs.toronto.edu/~kriz/cifar.html. The dataset contains 50,000 training images and 10,000 testing images, with each image being of dimensions 32x32 and in color. There are ten classes in the dataset: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. The project involves a multi-class classification problem.\n",
    "\n",
    "An observation in the dataset consists of an image and its corresponding label. The dataset has a total of 60,000 observations.\n",
    "\n",
    "The critical variables in the dataset are the images and their corresponding labels. The images are represented as a matrix of pixel values, while the labels are represented as integers corresponding to each of the ten classes.\n",
    "\n",
    "To prepare the dataset for analysis, some special handling may be needed, such as data cleaning and transformation. However, the CIFAR-10 dataset is already preprocessed, so no additional preprocessing steps are required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Why might your solution work? Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. \n",
    "\n",
    "The first step is to load the image data. Depending on the dataset, we will use keras or cv2\n",
    "libraries to load the data.\n",
    "\n",
    "Secondly, we will preprocess the data. We will resize the images to a standard size if the sizes\n",
    "of these images are not uniform. Then, we will normalize the images by dividing the image data\n",
    "by 255.0. Next, we will apply Principal Component Analysis to reduce the dimensions of data so\n",
    "that at least 80% of the explained variance could be covered. Sklearn library will be used to\n",
    "perform PCA. We will also split the dataset into a training set and a test set with the ratio of\n",
    "0.8/0.2 if the dataset has not been splitted after being loaded.\n",
    "\n",
    "Thirdly, we will train the machine learning models. We choose to use the Random Forest\n",
    "Classifier mode, which grows and merges multiple decision trees to achieve an accurate\n",
    "prediction, and train it on the training set. We will use grid search (GridSearchCV in sklearn) to\n",
    "select the best model with the best hyper-parameters.\n",
    "\n",
    "Lastly, we will test the model on test set using the metrics.classification_report function in\n",
    "sklearn, which will generate a classification report on metrics including recall, precision, and f-1\n",
    "score. Following the same procedure above, we will train and test a KNN model as a\n",
    "benchmark model against which our Random Forest Classifier will be compared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).\n",
    "\n",
    "We will primarily use the F-1 score to evaluate our models. Since F-1 score is the harmonic\n",
    "mean of precision and recall, it can provide a relatively more comprehensive evaluation on our\n",
    "model. Moreover, F-1 score takes into account class imbalance, so it will work well even if the\n",
    "classes of our dataset are imbalanced. The mathematical formula for F-1 score is\n",
    "2*Precision*Recall / (Precision + Recall). If the classes are well balanced, we will also\n",
    "incorporate accuracy for reference, which is calculated by (# of correct predictions) / (# of total\n",
    "predictions). It is a useful metric if the classes are decently balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project used different sets of data including images from different categories such as animals, objects, and cars. These datasets can be collected from CIFAR-10, and Kaggle. These data sets include enough images that include different classes of categories that are able to help us for the training. However, the biases that may be resulting from our analysis and training are inaccurate, which include some images not clear enough and bad image quality. To fix this issue, we also need to think about avoiding using poor-quality images for training to ensure the best result. Another bias that also might affect our final result is that our model might not ensure we get an accurate result, to fix the issue we also need to consider using an appropriate model for our project.\n",
    "\n",
    "In order to protect personal data, be only use public data from online, and we’ll ensure all the data that we used will not reveal any sensitive personal information.Meanwhile, we will use their data for this project research only and not for any commercial use. The dataset we’ll collect for this project is anonymous and unable to reveal any personal information. Thus, these processes ensured that personal privacy was not violated. Ethically, we will make sure to explain all of the analysis honestly and accurately. Since the datasets we’ll collect are public to use, we haven’t found any that are problematic in terms of data privacy and equitable impact. If any new datasets we added later could result problematic, we’ll mask all sensitive information that could/can reveal personal information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Keep the weekly meeting to make sure everything is up-to-date*\n",
    "* *Respect each other and be honest about the work that we have done or are doing*\n",
    "* *If conflicts happen, communicate first and try to understand each other*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/18  |  12 PM |  Read & Think about COGS 118A expectations; Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/20  |  12 PM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/22  | 12 PM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 3/05  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 3/12  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/18  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/22  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"Sanghvinote\"></a>1.[^](#Sanghvi, Kavish): Sanghvi, Kavish. “Image Classification Techniques.” Medium, Analytics Vidhya, 20 Mar. 2022, medium.com/analytics-vidhya/image-classification-techniques-83fd87011cac. <br> \n",
    "<a name=\"Nithyashree\"></a>2.[^](#Nithyashree): V, Nithyashree. “Image Classification Using Machine Learning.” Analytics Vidhya, 15 Mar. 2022, www.analyticsvidhya.com/blog/2022/01/image-classification-using-machine-learning/.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): “How Can You Tell the Difference between a Butterfly and a Moth?” The Library of Congress, 19 Nov. 2019, www.loc.gov/everyday-mysteries/zoology/item/how-can-you-tell-the-difference-between-a-butterfly-and-a-moth/#:~:text=Butterflies%20tend%20to%20fold%20their,smaller%20with%20drab%2Dcolored%20wings. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
