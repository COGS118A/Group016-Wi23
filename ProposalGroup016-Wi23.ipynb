{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Shiyuan Wang\n",
    "- Yuntian Wu\n",
    "- Xinhao Zhao\n",
    "- Wenyu Zhong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "For our project, we will apply various machine learning algorithms (including supervised machine learning algorithms and CNN) to classify X-ray images of patients' chests under different clinical conditions and make diagnoses automatically. We will also compare their accuracies at this particular task based on various error metrics and select the algorithms/models with the best performances. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Image classification using machine learning/AI methods these years has a primary focus in deep learning. Deep learning methods, particularly convolutional neural networks (CNNs), have shown impressive performance on a range of image classification tasks. In a study by LeCun et al., CNNs were shown to outperform traditional machine learning methods on the ImageNet benchmark dataset <a name=\"Lecunnote\"></a>[<sup>[1]</sup>](#Lecun). Another study by Russakovsky et al. demonstrated the effectiveness of transfer learning, which involves using pre-trained models on large datasets to improve performance on smaller datasets <a name=\"Russakovsky\"></a>[<sup>[2]</sup>](#Russakovsky). Image classification of clinical X-ray images has also been a focus of research. For example, a recent study showed that a deep learning model trained on X-ray images was able to accurately diagnose COVID-19 with high sensitivity and specificity, even when performed by non-experts<a name=\"Wang\"></a>[<sup>[3]</sup>](#Wang). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "During the COVID-19 pandemic, the scarcity of medical personnel has become an issue worth attention. According to a report by the International Council of Nurses, more than 1,500 nurses have died from COVID-19 worldwide, highlighting the dangers faced by frontline medical personnel.<a name=\"Council\"></a>[<sup>[4]</sup>](#Council)  In such circumstances where medical personnel are scarce, we seek to find a method, using machine learning, to reduce their workload so that the patients can be treated more efficiently. Specifically, we are focusing on the problem of whether we can rely on machine learning algorithms for diagnosing COVID-19 based on X-ray images of patients’ chests. This is quantifiable because we can use labeled image datasets and measure the algorithms’ accuracies (such as recall) in correctly classifying the images (e.g. classifying an image of a COVID patient as COVID-positive). The problem is also replicable in that once we have built our machine-learning models, people can use them to run more datasets to verify their usability, aside from our seven-thousand images. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The dataset comprises three folders (train, test, val) and includes subfolders for every image category (Normal/Pneumonia/Covid-19/Tuberculosis), with a total of 7135 x-ray images available.\n",
    " - Reference:https://data.mendeley.com/datasets/rscbjbr9sj/2\n",
    " - Size of the dataset: 7135 x-ray images in four ; four variables:Covid-19,Pneumonia,Tuberculosis, Normal; we will use those three variables to campare with nomal X-ray images\n",
    " - Observation: Each observation in this dataset is an image of either OCT or chest X-ray.\n",
    " - Critical Variables: The critical variables in this dataset are the image category (Normal/Pneumonia/Covid-19/Tuberculosis) for chest X-ray images and disease type (CNV, DME, DRUSEN, NORMAL) for OCT images.\n",
    " - Special Handling/Transformations/Cleaning: No special handling, transformations, or cleaning of this dataset is mentioned in the given information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Why might your solution work? Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. \n",
    "\n",
    "The first step is to load the image data. Depending on the dataset, we will use keras or cv2\n",
    "libraries to load the data.\n",
    "\n",
    "Secondly, we will preprocess the data. We will resize the images to a standard size if the sizes\n",
    "of these images are not uniform. Then, we will normalize the images by dividing the image data\n",
    "by 255.0. Next, we will apply Principal Component Analysis to reduce the dimensions of data so\n",
    "that at least 80% of the explained variance could be covered. Sklearn library will be used to\n",
    "perform PCA. We will also split the dataset into a training set and a test set with the ratio of\n",
    "0.8/0.2 if the dataset has not been splitted after being loaded.\n",
    "\n",
    "Thirdly, we will train the machine learning models. We choose to use the Random Forest\n",
    "Classifier mode, which grows and merges multiple decision trees to achieve an accurate\n",
    "prediction, and train it on the training set. We will use grid search (GridSearchCV in sklearn) to\n",
    "select the best model with the best hyper-parameters.\n",
    "\n",
    "Lastly, we will test the model on test set using the metrics.classification_report function in\n",
    "sklearn, which will generate a classification report on metrics including recall, precision, and f-1\n",
    "score. Following the same procedure above, we will train and test a KNN model as a\n",
    "benchmark model against which our Random Forest Classifier will be compared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).\n",
    "\n",
    "We will primarily use the F-1 score to evaluate our models. Since F-1 score is the harmonic\n",
    "mean of precision and recall, it can provide a relatively more comprehensive evaluation on our\n",
    "model. Moreover, F-1 score takes into account class imbalance, so it will work well even if the\n",
    "classes of our dataset are imbalanced. The mathematical formula for F-1 score is\n",
    "2*Precision*Recall / (Precision + Recall). If the classes are well balanced, we will also\n",
    "incorporate accuracy for reference, which is calculated by (# of correct predictions) / (# of total\n",
    "predictions). It is a useful metric if the classes are decently balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "NEW SECTION!\n",
    "\n",
    "Please show any preliminary results you have managed to obtain.\n",
    "\n",
    "Examples would include:\n",
    "\n",
    "Analyzing the suitability of a dataset or alogrithm for prediction/solving your problem\n",
    "Performing feature selection or hand-designing features from the raw data. Describe the features available/created and/or show the code for selection/creation\n",
    "Showing the performance of a base model/hyper-parameter setting. Solve the task with one \"default\" algorithm and characterize the performance level of that base model.\n",
    "Learning curves or validation curves for a particular model\n",
    "Tables/graphs showing the performance of different models/hyper-parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project used different sets of data including images from different categories such as animals, objects, and cars. These datasets can be collected from CIFAR-10, and Kaggle. These data sets include enough images that include different classes of categories that are able to help us for the training. However, the biases that may be resulting from our analysis and training are inaccurate, which include some images not clear enough and bad image quality. To fix this issue, we also need to think about avoiding using poor-quality images for training to ensure the best result. Another bias that also might affect our final result is that our model might not ensure we get an accurate result, to fix the issue we also need to consider using an appropriate model for our project.\n",
    "\n",
    "In order to protect personal data, be only use public data from online, and we’ll ensure all the data that we used will not reveal any sensitive personal information.Meanwhile, we will use their data for this project research only and not for any commercial use. The dataset we’ll collect for this project is anonymous and unable to reveal any personal information. Thus, these processes ensured that personal privacy was not violated. Ethically, we will make sure to explain all of the analysis honestly and accurately. Since the datasets we’ll collect are public to use, we haven’t found any that are problematic in terms of data privacy and equitable impact. If any new datasets we added later could result problematic, we’ll mask all sensitive information that could/can reveal personal information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Keep the weekly meeting to make sure everything is up-to-date*\n",
    "* *Respect each other and be honest about the work that we have done or are doing*\n",
    "* *If conflicts happen, communicate first and try to understand each other*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/18  |  12 PM |  Read & Think about COGS 118A expectations; Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/20  |  12 PM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/22  | 12 PM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 3/05  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 3/12  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/18  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/22  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"Lecunnote\"></a>1.[^](#Lecun): LeCun, Yann, et al. \"Deep Learning.\" Nature, vol. 521, no. 7553, 2015, pp. 436-444, doi: 10.1038/nature14539.<br> \n",
    "<a name=\"Russakovsky\"></a>2.[^](#Russakovsky): Russakovsky, Olga, et al. \"ImageNet Large Scale Visual Recognition Challenge.\" International Journal of Computer Vision, vol. 115, no. 3, 2015, pp. 211-252, doi: 10.1007/s11263-015-0816-y.<br>\n",
    "<a name=\"Wang\"></a>3.[^](#Wang): Wang, S., Kang, B., Ma, J., Zeng, X., Xiao, M., Guo, J., ... & Liang, Z. (2021). A deep learning algorithm using CT images to screen for Corona Virus Disease (COVID-19). medRxiv.<br>\n",
    "<a name=\"Council\"></a>4.[^](#Council): International Council of Nurses. \"COVID-19: ICN Calls for Urgent Support for Nurses to Ensure Global Health Security.\" 2021, https://www.icn.ch/system/files/2021-01/PR%20ICN%20calls%20for%20urgent%20support%20for%20nurses%20to%20ensure%20global%20health%20security.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
