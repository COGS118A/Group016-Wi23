{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iApb-74w0JQ7"
   },
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  X-ray Chest Image Classifications Using Surpervised Machine Learning Models and CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oTqKeLc0JQ9"
   },
   "source": [
    "# Names of Group 016\n",
    "\n",
    "\n",
    "- Shiyuan Wang\n",
    "- Yuntian Wu\n",
    "- Xinhao Zhao\n",
    "- Wenyu Zhong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9I42tVy0JQ9"
   },
   "source": [
    "# Abstract \n",
    "For our project, we will apply various machine learning algorithms (including supervised machine learning algorithms and CNN) to classify X-ray images of patients' chests under different clinical conditions and make diagnoses automatically. We will use CNN as the benchmark model, and compare its accuracy with those of the other supervised machine learning algorithms' accuracies based on various error metrics and select the algorithms/models with the best performances. We used `Recall` for performance/success of our study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9JXuynt0JQ-"
   },
   "source": [
    "# Background\n",
    "\n",
    "  During the COVID-19 pandemic, the scarcity of medical personnel has become an issue worth attention. According to a report by the International Council of Nurses, more than 1,500 nurses have died from COVID-19 worldwide, highlighting the dangers faced by frontline medical personnel.<a name=\"Council\"></a>[<sup>[4]</sup>](#Council)  In such circumstances where medical personnel are scarce, we seek to find a method, using machine learning, to reduce their workload so that the patients can be treated more efficiently. That is why we would like to use machine learning to classify X-ray images for diagnosing COVID-19 patients. \n",
    "  \n",
    "  Image classification using machine learning/AI methods these years has a primary focus in deep learning. Deep learning methods, particularly convolutional neural networks (CNNs), have shown impressive performance on a range of image classification tasks. In a study by LeCun et al., CNNs were shown to outperform traditional machine learning methods on the ImageNet benchmark dataset <a name=\"Lecunnote\"></a>[<sup>[1]</sup>](#Lecun). Another study by Russakovsky et al. demonstrated the effectiveness of transfer learning, which involves using pre-trained models on large datasets to improve performance on smaller datasets <a name=\"Russakovsky\"></a>[<sup>[2]</sup>](#Russakovsky). Image classification of clinical X-ray images has also been a focus of research. For example, a recent study showed that a deep learning model trained on X-ray images was able to accurately diagnose COVID-19 with high sensitivity and specificity, even when performed by non-experts<a name=\"Wang\"></a>[<sup>[3]</sup>](#Wang). For our project, we will comapre different supervised machine learning algorithms with the already established CNN approach for image classification by comparing their accuracies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "no-d7UBz0JQ-"
   },
   "source": [
    "# Problem Statement\n",
    "\n",
    "Specifically, we are focusing on the problem of whether we can rely on machine learning algorithms for diagnosing COVID-19 based on X-ray images of patients’ chests. This is quantifiable because we can use labeled image datasets and measure the algorithms’ accuracies (such as recall) in correctly classifying the images (e.g. classifying an image of a COVID patient as COVID-positive). The problem is also replicable in that once we have built our machine-learning models, people can use them to run more datasets to verify their usability, aside from our seven-thousand images. Finally, one potential ML solution to this problem is CNN (as discussed in the background section), which is a deep learning approach to tackle the task of image classification. Other than this, random forest is also a feasible machine learning algorithm for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa8UKmw50JQ_"
   },
   "source": [
    "# Data\n",
    "\n",
    "The dataset comprises two folders (train, test) and includes subfolders for every image category (Normal/Pneumonia/Covid-19/Tuberculosis), with a total of 7135 x-ray images available.\n",
    " - Reference: https://www.kaggle.com/datasets/jtiptj/chest-xray-pneumoniacovid19tuberculosis\n",
    " - Size of the dataset: 7135 x-ray images in four ; four variables:Covid-19,Pneumonia,Tuberculosis, Normal; after our data preprocessing, we take 450 images for each label.\n",
    " - Observation: Each observation in this dataset is an image of either OCT or chest X-ray.\n",
    " - Critical Variables: The critical variables in this dataset are the image category (Normal/Pneumonia/Covid-19/Tuberculosis) for chest X-ray images and disease type (CNV, DME, DRUSEN, NORMAL) for OCT images.\n",
    " - Special Handling/Transformations/Cleaning: Since we would like to use CNN, SVM, Random forest and KNN to predict the accuracy of the image classification. We did the following preprocessor to properly prepare the data before feeding it into the network. \n",
    "    1. Data Preprocessing: The code loads and resizes the images from the training and test directories and stores them in numpy arrays. The dictionary of classes is defined with corresponding labels, and the training data is sampled so that the count of each label is balanced. Only 450 data samples are taken from each label, and any additional data samples are ignored. The data is then transformed into a 2D numpy array. Please see the code below.\n",
    "    2. After conducting data cleaning procedures, which involved removing any corrupt or irrelevant data, we specifically resized the images in the dataset. Following this, we selected a subset of 450 images from each label based on predetermined criteria to solve the image imbalance problem. These measures were taken to ensure that the dataset used for subsequent analysis and modeling was of high quality and appropriate for the intended purposes. Therefore the images are already in a standard format, such as JPEG or PNG, and are typically normalized, resized, and transformed to ensure consistency. In addition, the images have already been categorized and labeled.\n",
    "    3. For answering the question of how to merge four sets of data into one, we specifically resized the images in the dataset. Following this, we selected a subset of only 450 images from the complete dataset based on predetermined criteria, such as image quality and content relevance. These measures were taken to ensure that the dataset used for subsequent analysis and modeling was of high quality and appropriate for the intended purposes.\n",
    "    4. Regarding class imbalance, the code ensures that the training set is balanced for each label by taking only 450 data samples from each label. A default dictionary is used to keep track of the count of each label, and any additional data samples are ignored. The proportion of classes in the training data is visualized using a pie chart.\n",
    "       Furthermore, the training and test datasets are usually provided separately, which means that there is no need to split the data manually. Additionally, if the images are already properly labeled, there is no need to remove any duplicates, outliers, or incorrect labels.\n",
    "\n",
    "In summary, for image classification tasks using CNNs, the need for data cleaning may be minimal or non-existent if the dataset is already properly preprocessed, labeled, and separated into training, validation, and test sets. However, it is always important to carefully review and understand the dataset before proceeding with training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xUeAzWO0JRA"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7Z82cHJ0JRB"
   },
   "outputs": [],
   "source": [
    "# define paths to train, validation, and test folders\n",
    "train_dir = \"/home/w1zhong/teams/group016/resize_train\"\n",
    "test_dir = \"/home/w1zhong/teams/group016/resize_test\"\n",
    "\n",
    "# Define dictionary of classes\n",
    "classes = {'COVID19': 0, 'NORMAL': 1, 'PNEUMONIA': 2, 'TURBERCULOSIS': 3}\n",
    "label_dict = {0: 'COVID19', 1: 'NORMAL', 2: 'PNEUMONIA', 3: 'TURBERCULOSIS'}\n",
    "\n",
    "# Define Empty list for train,test and val dataset and labels.\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "# Default dict used to keep track of the count of each label in order to make the training set balanced\n",
    "count = defaultdict(int)\n",
    "\n",
    "# Load training data\n",
    "for folder_name in os.listdir(train_dir):\n",
    "    folder_path = os.path.join(train_dir, folder_name)\n",
    "    for img_path in glob.glob(os.path.join(folder_path, \"*.*g\")):\n",
    "        label = classes[folder_name.upper()]\n",
    "        if count[label] > 460:\n",
    "            continue\n",
    "        count[label] += 1\n",
    "        img = load_img(img_path, target_size=(400, 400))\n",
    "        img_array = np.array(img)\n",
    "        train_data.append(img_array)\n",
    "        train_labels.append(label)\n",
    "        \n",
    "# Load test data\n",
    "for folder_name in os.listdir(test_dir):\n",
    "    folder_path = os.path.join(test_dir, folder_name)\n",
    "    for img_path in glob.glob(os.path.join(folder_path, \"*.*g\")):\n",
    "        img = load_img(img_path, target_size=(400, 400))\n",
    "        img_array = np.array(img)\n",
    "        test_data.append(img_array)\n",
    "        label = classes[folder_name.upper()]\n",
    "        test_labels.append(label)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Tranform data into Numpy Array and reshape to 2D\n",
    "train_data = np.array(train_data).reshape(len(train_data), -1)\n",
    "train_labels = np.array(train_labels)\n",
    "test_data = np.array(test_data).reshape(len(test_data), -1)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qje97fhc0JRC"
   },
   "source": [
    "#### We take only 460 data samples from each label so that the training set is balanced for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCC8e_aG0JRC",
    "outputId": "a6c66d68-0684-4026-9762-5f142cf2f22a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(train_labels).apply(lambda x: label_dict[x]).value_counts().plot(kind='pie', autopct=\"%0.0f%%\", title = 'Proportion of classes in training data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRUlI_5k0JRC"
   },
   "source": [
    "# Proposed Solution\n",
    "\n",
    "We propose to build classification model since we predict discrete class labels(4 type chest x-ray) which are normal, Pneumonia,Covid-19,Tuberculosis based on the dataset that contains 7135 x-ray images. Our solution will involve multiple machine learning algorithms which are KNN, SVM, random forest, and CNN. Our solution is applicable for several reasons:\n",
    "\n",
    "- CNN: We'll use CNN as our benchmark model to compare with K-NN, random forest, and SVM. CNN is designed to be spatially invariant in images, they can recognize the same patterns or features regardless of their position in the image. They are therefore well-equipped to deal with changes in chest X-ray images, which might change depending on the patient's position, the amount of exposure, and other elements.\n",
    "\n",
    "- SVM: SVM work by finding the hyperplane that best separates the classes in the dataset. We plan to use one vs rest for our multi-label classification task. The main reason that we choose to use SVM is because of its effectiveness for high-dimensional data, while our data has a large number dimensions, since each pixel in an image represents a feature. It’s robust to overfitting and good enough for performance which means it can perform well on unseen image. Therefore, SVM suits our image classification task very well. Moreover, We use SVM by implementing pca using sklearn PCA package. The primary reason is when we train SVM, it took a long time to finish due to the high dimension of data, then we implement the PCA which can help reduce the number of dimensions while still retaining important information and also PCA can be used to extract important features from images.\n",
    "\n",
    "- K-NN: It is a simple and effective on training algorithm. Since k-NN algorithm can handle non-linear decision boundaries, which is important when dealing with complex and heterogeneous data such as chest X-rays images. It can classify a new input image, examine the k-closest training data points to this image and assign the image to the most frequently occurring class. Moreover, We use K-NN by implementing pca using sklearn PCA package. The primary reason is it took a long time to train model due to the high dimension of data, then we implement the PCA which can help reduce the number of dimensions while still retaining important information and also PCA can be used to extract important features from images.\n",
    "\n",
    "- Random forest: It is an ensemble learning algorithm that constructs multiple decision trees and then aggregates their predictions. It’s a robust model. It has good enough performance and is fast to train. Each node selects from a random subset of features and the model can give estimates of what features are important. The image data usually a large number of features, and random forest itself can perform feature selection for us without the need for other forms of feature selection. Moreover, We use random forest by implementing pca using sklearn PCA package. The primary reason is it took a long time to train model due to the high dimension of data, then we implement the PCA which can help reduce the number of dimensions while still retaining important information and also PCA can be used to extract important features from images.\n",
    "\n",
    "To select the best hyper-parameters, we could perform grid search for each model, by doing k-fold cross-validation to validate the performance of different combinations of hyper parameters. Using these best hyper-parameters, we could evaluate the performance of each model by testing them on the test set. We plan to implement the models using the sklearn Python library in a way that is reproducible. In summary, our solution is applicable.\n",
    "\n",
    "How the solution will be tested:\n",
    "- To evaluate the performance of the solution, we will utilize a test set that is distinct and separate from the training set. The solution will then be tested on this set by applying the following evaluation metrics: f1-score, recall, precision, and accuracy. Specifically, we will focus on measuring recall, as this metric will indicate the proportion of positive cases that were correctly identified by the model. Then check which model has higher recall which means that more of the positive cases were correctly identified by the model. Ultimately, the model with the highest recall will be deemed the most effective solution for diagnosing COVID-19 based on X-ray images. The best model is the one with the highest recall scores among all the categories. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JptzNev70JRD"
   },
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "We will use recall as our primary evaluation metrics. Recall is also known as true positive rate, and it measures a model’s ability to correctly recognize all positive cases out of all actual positive cases in the datasets. It is calculated by TP / (TP + FN), where TP means the number of true positive cases and FN means the number of false negative cases. Recall is commonly used in classification tasks such as disease diagnosis. Recall suits our task well, because we want to prevent the cases of false negative from happening. For example, we don’t want positive patient to be classified as negative. Such mistake may generate undesirable outcome, since a positive patient can infect others, and also they usually need timely treatment for the fastest recovery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I76anBSB0JRE"
   },
   "source": [
    "# Results\n",
    "\n",
    "## Performance of Benchmark Model (CNN)\n",
    "The details can be found [here](https://github.com/COGS118A/Group016-Wi23/blob/main/CNN%20image%20classification%20(2).ipynb) in this file. \n",
    "\n",
    "We have implemented CNN for X-ray image classification as our benchmark model.\n",
    "1. Training: We used 10 epochs and picked recall as the evaluation metric.\n",
    "<p align=\"left\">\n",
    "<img src = 'img1.png' width = 70% height = 70%>\n",
    "</p >\n",
    "\n",
    "\n",
    "2. Classification results:\n",
    "\n",
    "<img src = 'img4.png' width = 70% height = 70%>\n",
    "\n",
    "From the classification results, we can see that the model predicts COVID-19, pneumonia, and tuberculosis well with a racall rate above 90%; however, for normal patients, the model does not work as well and ended up with a recall rate less than 50% despite our effort to balance out the traning image dataset. This is likely because normal patients' chest x-ray images vary in appearance, and some features of the normal patients' chest image are associated with pneumoina. A low recall rate for the normal category means many patients will be classified as having pneumonia while they do not. This is tolerable as our goal is to avoid low recall rates in classifying the other three categories, particularly COVID-19 because it is highly contagious. Other than this, the precision rate of the models are around 70% to 80%, with normal x-ray images having the hightest rate of above 90%. \n",
    "\n",
    "3. Confusion Matrix: \n",
    "\n",
    "<img src = 'img3.png' width = 70% height = 70%>\n",
    "\n",
    "We have found that for Normal patients’ chest X-ray images, the CNN model tends to predict them as pneumonia. In our case, we do not want a high false negative rate because this means a lot of patients will be contagious without being diagnosed. On the other hand, false positives can be tolerated. Therefore, this result is tolerable. Luckily, for COVID-19 (which is our main focus), the prediction result is satisfactory.\n",
    "\n",
    "\n",
    "4. Feature selection:\n",
    "\n",
    "<img src = 'img5.png' width = 70% height = 70%>\n",
    "\n",
    "We used tf.keras.preprocessing.image.ImageDataGenerator to extract feature data from the X-ray images. This class allows us to directly transfer raw images into manipulatable data for training, validating, and testing.\n",
    "\n",
    "\n",
    "4. Recall curve:\n",
    "\n",
    "![LearningCurve_recall.png](LearningCurve_recall.png)\n",
    "\n",
    "The recall curve indicates that, during the training process, the recall rates for the model increased the fastest during the first two epochs, and gradually increase until the 10th epoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a2Mbj-c0JRE"
   },
   "source": [
    "### Performance of Model #2 (Support Vector Machine)\n",
    "The details can be found [here](https://github.com/COGS118A/Group016-Wi23/blob/main/SVM_KNN_RFC.ipynb) in the first part of the file. \n",
    "\n",
    "1. Process: the process of grid search cross-validation (GridSearchCV) and support vector machine (SVM) using the SVC model. We will also examine the parameters used in this model and the best parameters obtained from the grid search.\n",
    "\n",
    "![image](training_svm.png)\n",
    "\n",
    "2. Classification results: We can observe from the provided image below, with the exception of PNEUMONIA(high recall 0.925641), the model has a low recall for all classes. The model misses a lot of COVID19 instances since the recall for COVID19 is only 0.009434. The recall for TUBERCULOSIS is also 0, meaning that no instances of this class were properly classified by the model. We can conclude that SVM is not a very good modeler of our dataset.\n",
    "\n",
    "![image](svm_table.png)\n",
    "\n",
    "3. Confusion matrix: We have 106 COVID-19 data, but we only predict 1 as COVID-19, while it misclassified 14 instances as NORMAL and 91 instances as PNEUMONIA. The model is not able to identify any cases of TUBERCULOSIS, all 41 TUBERCULOSIS labels misclassfication. 361 out of 390 PNEUMONIA patients predict correctly, the prediction result is satisfactory.\n",
    "\n",
    "![image](svm_confusion_matrix.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRpDKLVe0JRF"
   },
   "source": [
    "### Performance of Model #3 (K-NN)\n",
    "The details can be found [here](https://github.com/COGS118A/Group016-Wi23/blob/main/SVM_KNN_RFC.ipynb) in the second part of the file. \n",
    "\n",
    "![knn_code](knn_code.png)\n",
    "\n",
    "This code performs k-Nearest Neighbors classification on the input `train_data` using the `sklearn.neighbors.KNeighborsClassifier`. It first sets up a `param_grid` dictionary to search over different combinations of hyperparameters using the `GridSearchCV` function. Specifically, it varies the number of neighbors (n_neighbors) and the leaf size. The performance of the model is evaluated using the `recall_macro` score, which calculates the average recall across all classes. The function performs 3-fold cross-validation.\n",
    "\n",
    "The `model_grid.best_estimator_ is` used to store the best performing model based on the hyperparameters searched. This model is used to print the best recall and the corresponding best hyperparameters.\n",
    "\n",
    "![KNNRecall_Result](KNNRecall_Result.png)\n",
    "\n",
    "From the result we can make the following analysis regarding the performance of the KNN model:\n",
    "\n",
    "- The recall score of 0.8198 indicates that the model was able to correctly identify about 82% of all positive cases. This is a good result, but the actual performance of the model also depends on the specific problem and dataset being used. The value of best parameters indicates that the model was able to effectively prune the search space for finding nearest neighbors.\n",
    "\n",
    "- A high recall score is desirable in this case because it indicates that the  KNN model is correctly identifying a large proportion of COVID-positive cases in the dataset. This is important because false negatives (i.e., COVID-positive cases that are incorrectly identified as COVID-negative) can have serious consequences in terms of the diagnosis and treatment of COVID-19.Overall, the KNN model performed well with a recall score of 0.82, indicating that it was able to correctly identify a high proportion of positive cases. The hyperparameters used in training the model have contributed to this good performance.\n",
    "\n",
    "And then we analyzed other metrics, such as precision, accuracy, and F1 score, to obtain a more comprehensive understanding of the performance of KNN. \n",
    "\n",
    "![KNN_Precision](KNN_Precision.png)\n",
    "\n",
    "![KNN_Report](KNN_Report.png)\n",
    "\n",
    "From the KNN classification report, we can see that the precision, recall, and F1-score for the COVID19 class are 0.747899, 0.839623, and 0.791111, respectively. The precision indicates that 74.79% of the predicted COVID19 cases were actually COVID19. The recall suggests that the model correctly identified 83.96% of the actual COVID19 cases, while the F1-score represents the balance between precision and recall.\n",
    "\n",
    "Overall, the results suggest that the KNN model performs relatively well in predicting COVID19 cases, but there is still room for improvement. One possible way to improve the performance could be by incorporating more features or refining the feature selection process. It's also worth noting that the dataset used for training and testing the model can have an impact on the model's performance, and therefore, the results should be interpreted with caution.\n",
    "\n",
    "A confusion matrix could be calculated to show how the classifier performs on the test data. Our focuses on finding the best hyperparameters based on recall_macro score. We have 106 COVID-19 data. Out of these, 89 were predicted as COVID-19. However, 2 instances were misclassified as NORMAL, 6 instances as PNEUMONIA and 9 instances as TUBERCULOSIS. Out of 390 PNEUMONIA patients, 358 were predicted correctly. The prediction result is satisfactory.\n",
    "\n",
    "![KNN_Matrix](KNN_Matrix.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LEJUiCU0JRF"
   },
   "source": [
    "### Performance of Model #4 (Random Forest)\n",
    "The details can be found [here](https://github.com/COGS118A/Group016-Wi23/blob/main/SVM_KNN_RFC.ipynb) in the third part of the file. \n",
    "The Random Forest Classifier (RFC) model was trained and tested using the `RandomForestClassifier` from the `sklearn.ensemble` package. A `param_grid` dictionary was set up to perform a grid search over different combinations of hyperparameters using the `GridSearchCV` function. Specifically, it varied the maximum depth (`max_depth`) and the number of estimators (`n_estimators`). The performance of the model was evaluated using the `recall_macro` score, which calculates the average recall across all classes. The function performed 3-fold cross-validation.\n",
    "\n",
    "The `model_grid.best_estimator_` was used to store the best-performing model based on the hyperparameters searched. This model was used to print the best recall and the corresponding best hyperparameters:\n",
    "\n",
    "- Best recall: 0.8835908756438559\n",
    "- Best parameters: {'max_depth': 12, 'n_estimators': 100}\n",
    "\n",
    "#### Classification Report\n",
    "\n",
    "The classification report provides the following performance metrics for the Random Forest Classifier model:\n",
    "\n",
    "|                | precision | recall  | f1-score | support   |\n",
    "|----------------|-----------|---------|----------|-----------|\n",
    "| COVID19        | 0.848214  | 0.896226| 0.871560 | 106.000000 |\n",
    "| NORMAL         | 0.862903  | 0.457265| 0.597765 | 234.000000 |\n",
    "| PNEUMONIA      | 0.804878  | 0.930769| 0.863258 | 390.000000 |\n",
    "| TURBERCULOSIS  | 0.464286  | 0.951220| 0.624000 | 41.000000  |\n",
    "| **accuracy**   |           |         | 0.783398 | 0.783398   |\n",
    "| **macro avg**  | 0.745070  | 0.808870| 0.739146 | 771.000000 |\n",
    "| **weighted avg** | 0.810335 | 0.783398| 0.771099 | 771.000000 |\n",
    "\n",
    "#### Confusion Matrix\n",
    "\n",
    "We have 106 COVID-19 data, and predict 95 as COVID-19, while it misclassified 1 instances as NORMAL, 3 instances as PNEUMONIA and 7 instance as TUBERCULOSIS. 363 out of 390 PNEUMONIA patients predict correctly, the prediction result is satisfactory. A heatmap of the confusion matrix was plotted to visualize the performance of the model:\n",
    "\n",
    "![Confusion Matrix](cm_rf.png)\n",
    "\n",
    "#### Performance Analysis\n",
    "\n",
    "From the results, we can make the following analysis regarding the performance of the Random Forest Classifier model:\n",
    "\n",
    "1. The overall accuracy of 0.783398 indicates that the model was able to correctly classify about 78.34% of the instances in the test set.\n",
    "\n",
    "2. The recall_macro score of 0.808870 implies that the model was able to correctly identify approximately 80.89% of positive cases for each class, on average.\n",
    "\n",
    "3. The precision and recall scores for each class vary, with some classes like COVID19 and PNEUMONIA having relatively high recall scores, while others like NORMAL and TURBERCULOSIS have lower recall scores. This may suggest that the model is better at identifying certain classes compared to others.\n",
    "\n",
    "4. The best parameters found during the grid search were a `max_depth` of 12 and `n_estimators` of 100, indicating that these parameters yielded the best recall_macro score during cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZtejlpQ0JRF"
   },
   "source": [
    "### Analysis the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0N8LFCOP0JRG"
   },
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzX-lrRu0JRG"
   },
   "source": [
    "First point: In CNN, random forest, and KNN, we have observed that the recall scores are all satisfactory except for normal x-ray chest images. In the confusion matrix shown in the above sections, it seems some of the normal x-ray images are classified as pneumonia images. Upon inspecting our image data, we have found that the x-ray images of normal patients' chest and that of the pneumonia patients do look very similar. (The first image is the normal x-ray image and the second one is the pneumonia image.)\n",
    "\n",
    "![normal](normal.png)![pneumonia](pneumonia.png)\n",
    "\n",
    "Secondary point 1: Given that our group's primary focus is on classifying images to diagnose COVID-19, our emphasis is on having a high recall rate for classifying COVID-19 images. All three models above have done this job with a satifactory recall for COVID-19. In terms of the low recall rate of normal patients, this will lead to many patients being diagnosed to have pneumonia, which is not ideal. But this is far less harmful than having a high false negative rate for COVID-19 which means many COVID positive patients are not diagnosed and remain contagious in society. \n",
    "\n",
    "Secondary point 2: For SVM, The model's poor performance on the COVID-19 class indicates that it may require further data or fine-tuning to increase its capacity to correctly detect COVID-19 cases. While the model is performing relatively well in terms of identifying the NORMAL class's true positives, it is also making a significant number of false positive errors, which can have serious consequences in real-world applications. On the other hand, The model is unable to detect any TUBERCULOSIS cases, which may prevent patients from obtaining the proper care and may also cause the disease to spread. It implies that more fine-tuning or retraining of the model using a more varied and balanced dataset may be necessary to improve its ability to detect TUBERCULOSIS instances. For PNEUMONIA, the prediction result is satisfactory. We discussed together that SVM is the most suitable for the binary classification problems, which is the main reason for these problems.\n",
    "\n",
    "Overall, we can come up with the conclusion that CNN has the best performance among all models, which has the highest recall scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzRPbure0JRG"
   },
   "source": [
    "#### Limitations\n",
    "First of all, we try to fit a PCA transformation on both training and testing set, but this action will crash the kernel, until now, we couldn't find the reasons and solutions for this issue. That's the main reason we fit PCA transformation on training set.\n",
    "\n",
    "![image](pca.png)\n",
    "Based on the results of the different models, there are some limitations and problems with the work. Firstly, the recall score for COVID-19 is not very good for any of the models, which means there is a risk of misdiagnosis, and the models may miss some positive cases. This is especially problematic for COVID-19, as prompt and accurate diagnosis is crucial for preventing further spread of the disease.\n",
    "\n",
    "Additionally, the SVM model performed poorest among all the models, with a low recall score for COVID-19, while the CNN model tended to predict normal patients as having pneumonia, which is not ideal. These limitations suggest that the models may benefit from more fine-tuning of hyperparameters or additional data.\n",
    "\n",
    "It is possible that more data could improve the performance of the models, especially for COVID-19, as the number of positive cases in the dataset is relatively small compared to the other categories. Exploring more hyperparameters could also lead to better performance and more accurate predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzcP34lA0JRH"
   },
   "source": [
    "#### Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbmN0DLX0JRH"
   },
   "source": [
    "Our project used different sets of data including images from different categories of patients chest X-ray images. These datasets can be collected from Kaggle. These data sets include enough images that include different classes of categories that are able to help us for the training. However, the biases that may be resulting from our analysis and training are inaccurate, which include some images not clear enough and bad image quality. To fix this issue, we also need to think about avoiding using poor-quality images for training to ensure the best result. Another bias that also might affect our final result is that our model might not ensure we get an accurate result, to fix the issue we also need to consider using an appropriate model for our project.\n",
    "\n",
    "In order to protect personal data, be only use public data from online, and we’ll ensure all the data that we used will not reveal any sensitive personal information.Meanwhile, we will use their data for this project research only and not for any commercial use. The dataset we’ll collect for this project is anonymous and unable to reveal any personal information. Thus, these processes ensured that personal privacy was not violated. Ethically, we will make sure to explain all of the analysis honestly and accurately. Since the datasets we’ll collect are public to use, we haven’t found any that are problematic in terms of data privacy and equitable impact. If any new datasets we added later could result problematic, we’ll mask all sensitive information that could/can reveal personal information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEnrAEam0JRH"
   },
   "source": [
    "# Footnotes\n",
    "<a name=\"Lecunnote\"></a>1.[^](#Lecun): LeCun, Yann, et al. \"Deep Learning.\" Nature, vol. 521, no. 7553, 2015, pp. 436-444, doi: 10.1038/nature14539.<br> \n",
    "<a name=\"Russakovsky\"></a>2.[^](#Russakovsky): Russakovsky, Olga, et al. \"ImageNet Large Scale Visual Recognition Challenge.\" International Journal of Computer Vision, vol. 115, no. 3, 2015, pp. 211-252, doi: 10.1007/s11263-015-0816-y.<br>\n",
    "<a name=\"Wang\"></a>3.[^](#Wang): Wang, S., Kang, B., Ma, J., Zeng, X., Xiao, M., Guo, J., ... & Liang, Z. (2021). A deep learning algorithm using CT images to screen for Corona Virus Disease (COVID-19). medRxiv.<br>\n",
    "<a name=\"Council\"></a>4.[^](#Council): International Council of Nurses. \"COVID-19: ICN Calls for Urgent Support for Nurses to Ensure Global Health Security.\" 2021, https://www.icn.ch/system/files/2021-01/PR%20ICN%20calls%20for%20urgent%20support%20for%20nurses%20to%20ensure%20global%20health%20security.pdf.<br> \n",
    "<a name=\"Khan\"></a>5.Khan, Khizar. \"Lungs Disease Prediction: CNN Transfer Learning.\" Kaggle, Kaggle Inc., 23 Apr. 2021, https://www.kaggle.com/code/khizarkhan/lungs-disease-prediction-cnn-transfer-learning."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
