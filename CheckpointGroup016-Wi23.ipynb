{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "\n",
    "- Shiyuan Wang\n",
    "- Yuntian Wu\n",
    "- Xinhao Zhao\n",
    "- Wenyu Zhong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "For our project, we will apply various machine learning algorithms (including supervised machine learning algorithms and CNN) to classify X-ray images of patients' chests under different clinical conditions and make diagnoses automatically. We will use CNN as the benchmark model, and compare its accuracy with those of the other supervised machine learning algorithms' accuracies based on various error metrics and select the algorithms/models with the best performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "  During the COVID-19 pandemic, the scarcity of medical personnel has become an issue worth attention. According to a report by the International Council of Nurses, more than 1,500 nurses have died from COVID-19 worldwide, highlighting the dangers faced by frontline medical personnel.<a name=\"Council\"></a>[<sup>[4]</sup>](#Council)  In such circumstances where medical personnel are scarce, we seek to find a method, using machine learning, to reduce their workload so that the patients can be treated more efficiently. That is why we would like to use machine learning to classify X-ray images for diagnosing COVID-19 patients. \n",
    "  \n",
    "  Image classification using machine learning/AI methods these years has a primary focus in deep learning. Deep learning methods, particularly convolutional neural networks (CNNs), have shown impressive performance on a range of image classification tasks. In a study by LeCun et al., CNNs were shown to outperform traditional machine learning methods on the ImageNet benchmark dataset <a name=\"Lecunnote\"></a>[<sup>[1]</sup>](#Lecun). Another study by Russakovsky et al. demonstrated the effectiveness of transfer learning, which involves using pre-trained models on large datasets to improve performance on smaller datasets <a name=\"Russakovsky\"></a>[<sup>[2]</sup>](#Russakovsky). Image classification of clinical X-ray images has also been a focus of research. For example, a recent study showed that a deep learning model trained on X-ray images was able to accurately diagnose COVID-19 with high sensitivity and specificity, even when performed by non-experts<a name=\"Wang\"></a>[<sup>[3]</sup>](#Wang). For our project, we will comapre different supervised machine learning algorithms with the already established CNN approach for image classification by comparing their accuracies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Specifically, we are focusing on the problem of whether we can rely on machine learning algorithms for diagnosing COVID-19 based on X-ray images of patients’ chests. This is quantifiable because we can use labeled image datasets and measure the algorithms’ accuracies (such as recall) in correctly classifying the images (e.g. classifying an image of a COVID patient as COVID-positive). The problem is also replicable in that once we have built our machine-learning models, people can use them to run more datasets to verify their usability, aside from our seven-thousand images. Finally, one potential ML solution to this problem is CNN (as discussed in the background section), which is a deep learning approach to tackle the task of image classification. Other than this, random forest is also a feasible machine learning algorithm for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The dataset comprises three folders (train, test, val) and includes subfolders for every image category (Normal/Pneumonia/Covid-19/Tuberculosis), with a total of 7135 x-ray images available.\n",
    " - Reference: https://www.kaggle.com/datasets/jtiptj/chest-xray-pneumoniacovid19tuberculosis\n",
    " - Size of the dataset: 7135 x-ray images in four ; four variables:Covid-19,Pneumonia,Tuberculosis, Normal; we will use those three variables to campare with nomal X-ray images\n",
    " - Observation: Each observation in this dataset is an image of either OCT or chest X-ray.\n",
    " - Critical Variables: The critical variables in this dataset are the image category (Normal/Pneumonia/Covid-19/Tuberculosis) for chest X-ray images and disease type (CNV, DME, DRUSEN, NORMAL) for OCT images.\n",
    " - Special Handling/Transformations/Cleaning: Since we would like to use CNN, SVM, Random forest and KNN to predict the accuracy of the image classification. We did the following preprocessor to properly prepare the data before feeding it into the network. \n",
    "    1. Data Preprocessing: We resized the images to a fixed size. Please see the code below.\n",
    "    2.  Data cleaning may not always be necessary for our dataset. This is because image datasets used for CNNs are usually preprocessed and pre-categorized. The images are already in a standard format, such as JPEG or PNG, and are typically normalized, resized, and transformed to ensure consistency. In addition, the images have already been categorized and labeled, so there is no need to manually clean and categorize the data.\n",
    "        Furthermore, the training, validation, and test datasets are usually provided separately, which means that there is no need to split the data manually. Additionally, if the images are already properly labeled, there is no need to remove any duplicates, outliers, or incorrect labels.\n",
    "        In summary, for image classification tasks using CNNs, the need for data cleaning may be minimal or non-existent if the dataset is already properly preprocessed, labeled, and separated into training, validation, and test sets. However, it is always important to carefully review and understand the dataset before proceeding with training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder path: /home/w1zhong/teams/group016/test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_name = \"test\"  # Replace with the name of your folder\n",
    "folder_path = os.path.abspath(folder_name)\n",
    "\n",
    "print(\"Folder path:\", folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Set the new size\n",
    "new_size = (400, 400)\n",
    "\n",
    "# Set the input and output folder paths\n",
    "input_folder = '/home/w1zhong/teams/group016/val/TURBERCULOSIS'\n",
    "output_folder = '/home/w1zhong/teams/group016/resize_val/TURBERCULOSIS'\n",
    "\n",
    "# Create the output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop over all the files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    # Check if the file is an image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "        # Open the image\n",
    "        image = Image.open(os.path.join(input_folder, filename))\n",
    "        # Convert RGBA images to RGB mode\n",
    "        if image.mode == 'RGBA':\n",
    "            image = image.convert('RGB')\n",
    "        # Resize the image\n",
    "        resized_image = image.resize(new_size)\n",
    "        # Convert the image mode to RGB if it's not already in RGB mode\n",
    "        if resized_image.mode != 'RGB':\n",
    "            resized_image = resized_image.convert('RGB')\n",
    "        # Save the resized image to the output folder\n",
    "        resized_image.save(os.path.join(output_folder, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "We propose to build classification model since we predict discrete class labels(4 type chest x-ray) which are normal, Pneumonia,Covid-19,Tuberculosis based on the dataset that contains 7135 x-ray images. Our solution will involve multiple machine learning algorithms which are KNN, SVM, random forest, and CNN. Our solution is applicable for several reasons:\n",
    "\n",
    "- CNN: We'll use CNN as our benchmark model to compare with K-NN, random forest, and SVM. CNN is designed to be spatially invariant in images, they can recognize the same patterns or features regardless of their position in the image. They are therefore well-equipped to deal with changes in chest X-ray images, which might change depending on the patient's position, the amount of exposure, and other elements.\n",
    "\n",
    "- K-NN: It is a simple and effective on training algorithm. Since k-NN algorithm can handle non-linear decision boundaries, which is important when dealing with complex and heterogeneous data such as chest X-rays images. It can classify a new input image, examine the k-closest training data points to this image and assign the image to the most frequently occurring class. \n",
    "\n",
    "- Random forest: It is an ensemble learning algorithm that constructs multiple decision trees and then aggregates their predictions. It’s a robust model. It has good enough performance and is fast to train. Each node selects from a random subset of features and the model can give estimates of what features are important. The image data usually a large number of features, and random forest itself can perform feature selection for us without the need for other forms of feature selection.\n",
    "\n",
    "- SVM: SVM work by finding the hyperplane that best separates the classes in the dataset. We plan to use one vs rest for our multi-label classification task. The main reason that we choose to use SVM is because of its effectiveness for high-dimensional data, while our data has a large number dimensions, since each pixel in an image represents a feature. It’s robust to overfitting and good enough for performance which means it can perform well on unseen image. Therefore, SVM suits our image classification task very well.\n",
    "\n",
    "To select the best hyper-parameters, we could perform grid search for each model, by doing k-fold cross-validation to validate the performance of different combinations of hyper parameters. Using these best hyper-parameters, we could evaluate the performance of each model by testing them on the test set. We plan to implement the models using the sklearn Python library in a way that is reproducible. In summary, our solution is applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "We will use recall as our primary evaluation metrics. Recall is also known as true positive rate, and it measures a model’s ability to correctly recognize all positive cases out of all actual positive cases in the datasets. It is calculated by TP / (TP + FN), where TP means the number of true positive cases and FN means the number of false negative cases. Recall is commonly used in classification tasks such as disease diagnosis. Recall suits our task well, because we want to prevent the cases of false negative from happening. For example, we don’t want positive patient to be classified as negative. Such mistake may generate undesirable outcome, since a positive patient can infect others, and also they usually need timely treatment for the fastest recovery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "We have implemented CNN for X-ray image classification.\n",
    "1. Training: We used 10 epochs and picked recall as the evaluation metric.\n",
    "![img1](img1.png)\n",
    "\n",
    "2. Validation and test accuracies of the best model:\n",
    "![img2](img2.png)\n",
    "\n",
    "3. Classification results:\n",
    "![img4](img4.png)\n",
    "\n",
    "4. Confusion Matrix: We have found that for Normal patients’ chest X-ray images, the CNN model tends to predict them as pneumonia. In our case, we do not want a high false negative rate because this means a lot of patients will be contagious without being diagnosed. On the other hand, false positives can be tolerated. Therefore, this result is tolerable. Luckily, for COVID-19 (which is our main focus), the prediction result is satisfactory.\n",
    "\n",
    "![img3](img3.png)\n",
    "\n",
    "Feature selection:\n",
    "We used tf.keras.preprocessing.image.ImageDataGenerator to extract feature data from the X-ray images. This class allows us to directly transfer raw images into manipulatable data for training, validating, and testing.\n",
    "![img5](img5.png)\n",
    "\n",
    "Learning curves for a particular model:\n",
    "![LearningCurve_loss.png](LearningCurve_loss.png)\n",
    "![LearningCurve_recall.png](LearningCurve_recall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project used different sets of data including images from different categories such as animals, objects, and cars. These datasets can be collected from CIFAR-10, and Kaggle. These data sets include enough images that include different classes of categories that are able to help us for the training. However, the biases that may be resulting from our analysis and training are inaccurate, which include some images not clear enough and bad image quality. To fix this issue, we also need to think about avoiding using poor-quality images for training to ensure the best result. Another bias that also might affect our final result is that our model might not ensure we get an accurate result, to fix the issue we also need to consider using an appropriate model for our project.\n",
    "\n",
    "In order to protect personal data, be only use public data from online, and we’ll ensure all the data that we used will not reveal any sensitive personal information.Meanwhile, we will use their data for this project research only and not for any commercial use. The dataset we’ll collect for this project is anonymous and unable to reveal any personal information. Thus, these processes ensured that personal privacy was not violated. Ethically, we will make sure to explain all of the analysis honestly and accurately. Since the datasets we’ll collect are public to use, we haven’t found any that are problematic in terms of data privacy and equitable impact. If any new datasets we added later could result problematic, we’ll mask all sensitive information that could/can reveal personal information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Keep the weekly meeting to make sure everything is up-to-date*\n",
    "* *Respect each other and be honest about the work that we have done or are doing*\n",
    "* *If conflicts happen, communicate first and try to understand each other*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/18  |  12 PM |  Read & Think about COGS 118A expectations; Brainstorm topics/questions   | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/20  |  12 PM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/22  | 12 PM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 3/05  | 6 PM  | Import & Wrangle Data ,do some EDA | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 3/15  | 12 PM  | Finalize wrangling/EDA; Begin programming for project  | Discuss/edit project code; Complete project |\n",
    "| 3/18  | 12 PM  | Complete analysis; Draft results/conclusion/discussion | Discuss/edit full project |\n",
    "| 3/22  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"Lecunnote\"></a>1.[^](#Lecun): LeCun, Yann, et al. \"Deep Learning.\" Nature, vol. 521, no. 7553, 2015, pp. 436-444, doi: 10.1038/nature14539.<br> \n",
    "<a name=\"Russakovsky\"></a>2.[^](#Russakovsky): Russakovsky, Olga, et al. \"ImageNet Large Scale Visual Recognition Challenge.\" International Journal of Computer Vision, vol. 115, no. 3, 2015, pp. 211-252, doi: 10.1007/s11263-015-0816-y.<br>\n",
    "<a name=\"Wang\"></a>3.[^](#Wang): Wang, S., Kang, B., Ma, J., Zeng, X., Xiao, M., Guo, J., ... & Liang, Z. (2021). A deep learning algorithm using CT images to screen for Corona Virus Disease (COVID-19). medRxiv.<br>\n",
    "<a name=\"Council\"></a>4.[^](#Council): International Council of Nurses. \"COVID-19: ICN Calls for Urgent Support for Nurses to Ensure Global Health Security.\" 2021, https://www.icn.ch/system/files/2021-01/PR%20ICN%20calls%20for%20urgent%20support%20for%20nurses%20to%20ensure%20global%20health%20security.pdf.\n",
    "<a name=\"Khan\"></a>5.[^](#Khan) Khan, Khizar. \"Lungs Disease Prediction: CNN Transfer Learning.\" Kaggle, Kaggle Inc., 23 Apr. 2021, https://www.kaggle.com/code/khizarkhan/lungs-disease-prediction-cnn-transfer-learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
